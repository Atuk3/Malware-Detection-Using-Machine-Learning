import json
import os
import io
from flask import Flask,render_template, request, jsonify,flash,url_for,redirect,session,make_response
from sqlalchemy import true
from flask_wtf import FlaskForm
from wtforms import FileField, SubmitField
from werkzeug.utils import secure_filename
from wtforms.validators import InputRequired
import pefile
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import pickle
import math
import joblib
from sklearn.pipeline import Pipeline
import numpy as np
from io import BytesIO


app=Flask(__name__)
app.config['SECRET_KEY']='david'
app.config['UPLOAD_FOLDER']='static/files'

allowed_extension="exe"



@app.route('/', methods=['GET', 'POST'])
@app.route('/home', methods=['GET', 'POST'])

def home():
    file_path=None
    error=None
    file_status=None
    prediction_accuracy=None
    if request.method == "POST":
        file=request.files['file']
        filename=file.filename
        if not filename.endswith('.exe'):
            flash('Invalid File Selected.. Choose a .exe file', category='error')
            return redirect(url_for('home'))
        
        
        data=file.read()
        pe = pefile.PE(data = data)
        img = None
        features,file_data= features_extraction(data, pe) 
        y_pred,pred_prob = getPredictions(file_data)
        if y_pred==0:
            file_status="Benign"
            print("This file is safe")
            prediction_accuracy=(pred_prob[0][0])*100
            print(prediction_accuracy)
        
        if y_pred==1:
            file_status="Malware"
            print("This file is harmful and contains malware")
            prediction_accuracy=(pred_prob[0][1])*100
            print(prediction_accuracy)
            
        
        print(file_status)
        
        # if pred == 1:
        # img_path=createGreyScaleImage(path)
        # img = cnn_predict(img_path)
        # print(img)
        # else:
        # print("Normal FIle")

        return render_template('report.html',filename=filename,file_status=file_status,features=features,prediction_accuracy=prediction_accuracy)
       
       
        
      
        
    
        

   
    return render_template('index.html')


  


@app.route('/about', methods=['GET', 'POST'])
def about():
    return render_template('about.html')

@app.route('/tutorial', methods=['GET', 'POST'])
def tutorial():
    return render_template('tutorial.html')



def features_extraction(data, pe):
     
      # File Header Features
      Machine=pe.FILE_HEADER.Machine
    
      TimeDateStamp=pe.FILE_HEADER.TimeDateStamp
      Characteristics=pe.FILE_HEADER.Characteristics
      SizeOfOptionalHeader = pe.FILE_HEADER.SizeOfOptionalHeader

      #DOS Header Features
      e_minalloc = pe.DOS_HEADER.e_minalloc
      e_lfanew = pe.DOS_HEADER.e_lfanew
      e_maxalloc = pe.DOS_HEADER.e_maxalloc

      # Optional Header Features
      Magic = pe.OPTIONAL_HEADER.Magic
      MajorLinkerVersion = pe.OPTIONAL_HEADER.MajorLinkerVersion
      ImageBase = pe.OPTIONAL_HEADER.ImageBase
      SectionAlignment = pe.OPTIONAL_HEADER.SectionAlignment
      MajorOSVersion = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
      MinorOSVersion = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
      MajorSubsystemVersion = pe.OPTIONAL_HEADER.MajorSubsystemVersion
      MinorSubsystemVersion = pe.OPTIONAL_HEADER.MinorSubsystemVersion
      Subsystem = pe.OPTIONAL_HEADER.Subsystem
      Dll = pe.OPTIONAL_HEADER.DllCharacteristics
      StackReserveSize = pe.OPTIONAL_HEADER.SizeOfStackReserve
      MajorImageVersion = pe.OPTIONAL_HEADER.MajorImageVersion
      SizeOfHeaders = pe.OPTIONAL_HEADER.SizeOfHeaders
      FileAlignment = pe.OPTIONAL_HEADER.FileAlignment

      
      # Suspicious Import Functions
      with open('suspicious_functions.txt') as f:
        content=f.readlines()
      content=[x.strip() for x in content]
      suspicious_imports = 0
      try:
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                for func in entry.imports:
                    if func.name.decode('utf-8') in content:
                        suspicious_imports+=1
            SuspiciousImportFunctions =  suspicious_imports
      except AttributeError:
            SuspiciousImportFunctions=0



      # Section Features
      characteristics = map(lambda x:x.Characteristics, pe.sections)
      SectionMaxChar = max(characteristics)
      
      entropy = map(lambda x:x.get_entropy(), pe.sections)
      SectionMinEntropy = min(entropy)
    
      
      # Directory Features
      DirectoryEntryImport = (len(pe.DIRECTORY_ENTRY_IMPORT))
       
   
     
    
      
      #The important feature data of the file for the machine learning is stored in the file_data array
    
      file_data = [e_minalloc, e_lfanew, e_maxalloc, Machine, TimeDateStamp, Characteristics, SizeOfOptionalHeader, Magic, MajorLinkerVersion, ImageBase, SectionAlignment, MajorOSVersion, MinorOSVersion, MajorSubsystemVersion, MinorSubsystemVersion, Subsystem, Dll, StackReserveSize, MajorImageVersion, SizeOfHeaders, FileAlignment, SuspiciousImportFunctions, SectionMaxChar, SectionMinEntropy, DirectoryEntryImport]
      file_data = np.reshape(file_data,(1,-1))
      
      features={}

      #File size
      file_datum = io.BytesIO(data)
      features["size"] = len(file_datum.getvalue())
   
      api_calls=[]
      for entry in pe.DIRECTORY_ENTRY_IMPORT:
        api_calls.append(entry.dll.decode())
      features["api_calls"]= api_calls

    #   File extension
    
      file_extension=".exe"
      features["file_extension"] = file_extension
    


      # File entropy
    #   with open(file_path, "rb") as f:
    #     data = f.read()
    #     entropy = 0
    #     for b in range(256):
    #       p_b = float(data.count(bytes([b]))) / len(data)
    #       if p_b > 0:
    #           entropy += - p_b * math.log(p_b, 2)
    #     features["entropy"] = entropy
      
      return features,file_data

def getPredictions(data):
  model = joblib.load('Models\RFC_model.pkl')
  
  y_pred = model.predict(data)
  pred_prob= model.predict_proba(data)
  

  
  return y_pred,pred_prob


# def getPredictions(data):
#   model = joblib.load('RFC_model.pkl')
  
#   y_pred = model.predict(data)
#   if y_pred==0:
#     print("This file is safe")
#   if y_pred==1:
#         print("This file is harmful and contains malware")
        

  
#   return y_pred


# def getBinaryData(filename):
# 	"""
# 	Extract byte values from binary executable file and store them into list
# 	:param filename: executable file name
# 	:return: byte value list
# 	"""

# 	binary_values = []

# 	with open(filename, 'rb') as fileobject:

# 		# read file byte by byte
# 		data = fileobject.read(1)

# 		while data != b'':
# 			binary_values.append(ord(data))
# 			data = fileobject.read(1)
# 	return binary_values

# def createGreyScaleImage(filename, width=None):
    
#     greyscale_data = getBinaryData(filename)
#     size = get_size(len(greyscale_data), width)
#     try:
#         image = Image.new('L', size)
#         image.putdata(greyscale_data)
#         # setup output filename
#         dirname = os.path.dirname(filename)
#         name, _ = os.path.splitext(os.path.basename(filename))
#         imagename = os.path.join(dirname, name + '' '.png')
#         os.makedirs(os.path.dirname(imagename), exist_ok=True)
       
#         image.save(imagename)
#         print("The file", imagename, "saved.")

#         img_path = imagename
#         print(img_path)
#         return img_path
#     except Exception as err:
#         print(err)
#         print("Didnt save anything")
#     print(image)  # Add this line to print the image object

# def get_size(data_length, width=None):
# 	# source Malware images: visualization and automatic classification by L. Nataraj
# 	# url : http://dl.acm.org/citation.cfm?id=2016908

# 	if width is None: # with don't specified any with value

# 		size = data_length

# 		if (size < 10240):
# 			width = 32
# 		elif (10240 <= size <= 10240 * 3):
# 			width = 64
# 		elif (10240 * 3 <= size <= 10240 * 6):
# 			width = 128
# 		elif (10240 * 6 <= size <= 10240 * 10):
# 			width = 256
# 		elif (10240 * 10 <= size <= 10240 * 20):
# 			width = 384
# 		elif (10240 * 20 <= size <= 10240 * 50):
# 			width = 512
# 		elif (10240 * 50 <= size <= 10240 * 100):
# 			width = 768
# 		else:
# 			width = 1024

# 		height = int(size / width) + 1

# 	else:
# 		width  = int(math.sqrt(data_length)) + 1
# 		height = width

# 	return (width, height)


# #PreProcess
# from io import BytesIO
# from PIL import Image
# model = None
# output_dict = {'Adialer.C': 0,
#  'Agent.FYI': 1,
#  'Allaple.A': 2,
#  'Allaple.L': 3,
#  'Alueron.gen!J': 4,
#  'Autorun.K': 5,
#  'C2LOP.P': 6,
#  'C2LOP.gen!g': 7,
#  'Dialplatform.B': 8,
#  'Dontovo.A': 9,
#  'Fakerean': 10,
#  'Instantaccess': 11,
#  'Lolyda.AA1': 12,
#  'Lolyda.AA2': 13,
#  'Lolyda.AA3': 14,
#  'Lolyda.AT': 15,
#  'Malex.gen!J': 16,
#  'Obfuscator.AD': 17,
#  'Rbot!gen': 18,
#  'Skintrim.N': 19,
#  'Swizzor.gen!E': 20,
#  'Swizzor.gen!I': 21,
#  'VB.AT': 22,
#  'Wintrim.BX': 23,
#  'Yuner.A': 24}

# def load_model():
#   model =  tf.keras.models.load_model("malware_family_model.h5")
#   print("Model loaded...")
#   return model

# def cnn_predict(imagepath):
#     global model
#     if model is None:
#         model = load_model()
#     image = cv2.imread(imagepath)
#     image = cv2.resize(image, (64, 64))
#     image = img_to_array(image)
#     image = np.expand_dims(image, axis=0)
#     res = model.predict(image)
#     pred_class = np.argmax(res, axis=1)
#     ax = model.predict(image)
#     return get_key(pred_class)

# def get_key(val):
#     for key, value in output_dict.items():
#          if val == value:
#              return key
 
#     return "key doesn't exist"

#  # extract content
# path="/home/owamagbe/Documents/Comp3000 Project/Malware-Detection-Using-Machine-Learning/Malware family sample/RAT/NJRat.exe"
# img_path=createGreyScaleImage(path)
# img = cnn_predict(img_path)
# print(img)
# else:
# print("Normal FIle")


if __name__ == '__main__':
    app.run(debug=true)