# Import necessary libraries
import json
import os
import io
from flask import Flask,render_template, request, jsonify,flash,url_for,redirect,session,make_response

from flask_wtf import FlaskForm
from wtforms import FileField, SubmitField
from werkzeug.utils import secure_filename
from wtforms.validators import InputRequired
import pefile
import numpy as np 
import pandas as pd 
import pickle
import math
import joblib
from sklearn.pipeline import Pipeline
import numpy as np
from io import BytesIO

import pefile
import numpy as np
import pandas as pd
import pickle
import math
import joblib
from sklearn.pipeline import Pipeline
import numpy as np

from keras.applications import imagenet_utils
import tensorflow as tf 
import itertools
import pefile
import cv2
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from keras.utils import img_to_array
from PIL import Image

# Initialize Flask application
app=Flask(__name__)

# Set Flask application configurations
app.config['SECRET_KEY']='david'
app.config['UPLOAD_FOLDER']='static/files'

# Define allowed file extension for uploaded files

allowed_extension="exe"


# Define the homepage route
@app.route('/', methods=['GET', 'POST'])
@app.route('/home', methods=['GET', 'POST'])

def home():
    # Set initial values for variables
    file_path=None
    error=None
    file_status=None
    file_comment=None
    prediction_accuracy=None
    file=None
    # Handle POST requests for file upload
    if request.method == "POST":
        file=request.files['file']
        filename=file.filename
        # Check if the uploaded file has the allowed file extension
        if not filename.endswith('.exe'):
            flash('Invalid File Selected.. Choose a .exe file', category='error')
            return redirect(url_for('home'))
        
              # Extract features from the uploaded file
        data=file.read()
        pe = pefile.PE(data = data)
        img = None
        features,file_data= features_extraction(data, pe) 
        y_pred,pred_prob = getPredictions(file_data)
          # Get predictions for the uploaded file
        if y_pred==0:
            file_status="Benign"
            file_comment="This file is safe"
            prediction_accuracy=(pred_prob[0][0])*100
            print(prediction_accuracy)
        
        if y_pred==1:
            file_status="Malware"
            file_comment="This file is harmful"
            prediction_accuracy=(pred_prob[0][1])*100
            print(prediction_accuracy)
            file.seek(0)
            
            
            

            
        
        print(file_status)
        
       # Render the report template with the results

        return render_template('report.html',filename=filename,file_status=file_status,file_comment=file_comment,features=features,prediction_accuracy=prediction_accuracy)
       
       
        
      
        
    
        

   # Render the homepage template for GET requests
    return render_template('index.html')


  
# Define the about page route

@app.route('/about', methods=['GET', 'POST'])
def about():
    return render_template('about.html')

# Define the tutorial page route

@app.route('/tutorial', methods=['GET', 'POST'])
def tutorial():
    return render_template('tutorial.html')


# Function to extract features from a file
def features_extraction(data, pe):
     
      # File Header Features
      Machine=pe.FILE_HEADER.Machine
    
      TimeDateStamp=pe.FILE_HEADER.TimeDateStamp
      Characteristics=pe.FILE_HEADER.Characteristics
      SizeOfOptionalHeader = pe.FILE_HEADER.SizeOfOptionalHeader

      #DOS Header Features
      e_minalloc = pe.DOS_HEADER.e_minalloc
      e_lfanew = pe.DOS_HEADER.e_lfanew
      e_maxalloc = pe.DOS_HEADER.e_maxalloc

      # Optional Header Features
      Magic = pe.OPTIONAL_HEADER.Magic
      MajorLinkerVersion = pe.OPTIONAL_HEADER.MajorLinkerVersion
      ImageBase = pe.OPTIONAL_HEADER.ImageBase
      SectionAlignment = pe.OPTIONAL_HEADER.SectionAlignment
      MajorOSVersion = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
      MinorOSVersion = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
      MajorSubsystemVersion = pe.OPTIONAL_HEADER.MajorSubsystemVersion
      MinorSubsystemVersion = pe.OPTIONAL_HEADER.MinorSubsystemVersion
      Subsystem = pe.OPTIONAL_HEADER.Subsystem
      Dll = pe.OPTIONAL_HEADER.DllCharacteristics
      StackReserveSize = pe.OPTIONAL_HEADER.SizeOfStackReserve
      MajorImageVersion = pe.OPTIONAL_HEADER.MajorImageVersion
      SizeOfHeaders = pe.OPTIONAL_HEADER.SizeOfHeaders
      FileAlignment = pe.OPTIONAL_HEADER.FileAlignment

      
      # Suspicious Import Functions
      with open('suspicious_functions.txt') as f:
        content=f.readlines()
      content=[x.strip() for x in content]
      suspicious_imports = 0
      try:
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                for func in entry.imports:
                    if func.name.decode('utf-8') in content:
                        suspicious_imports+=1
            SuspiciousImportFunctions =  suspicious_imports
      except AttributeError:
            SuspiciousImportFunctions=0



      # Section Features
      characteristics = map(lambda x:x.Characteristics, pe.sections)
      SectionMaxChar = max(characteristics)
      
      entropy = map(lambda x:x.get_entropy(), pe.sections)
      SectionMinEntropy = min(entropy)
    
      
      # Directory Features
      DirectoryEntryImport = (len(pe.DIRECTORY_ENTRY_IMPORT))
       
   
     
    
      
      #The important feature data of the file for the machine learning is stored in the file_data array
    
      file_data = [e_minalloc, e_lfanew, e_maxalloc, Machine, TimeDateStamp, Characteristics, SizeOfOptionalHeader, Magic, MajorLinkerVersion, ImageBase, SectionAlignment, MajorOSVersion, MinorOSVersion, MajorSubsystemVersion, MinorSubsystemVersion, Subsystem, Dll, StackReserveSize, MajorImageVersion, SizeOfHeaders, FileAlignment, SuspiciousImportFunctions, SectionMaxChar, SectionMinEntropy, DirectoryEntryImport]
      file_data = np.reshape(file_data,(1,-1))
      
      features={}

      #File size
      file_datum = io.BytesIO(data)
      features["size"] = len(file_datum.getvalue())
   
      api_calls=[]
      for entry in pe.DIRECTORY_ENTRY_IMPORT:
        api_calls.append(entry.dll.decode())
      features["api_calls"]= api_calls

    #   File extension
    
      file_extension=".exe"
      features["file_extension"] = file_extension
    


   
      
      return features,file_data

def getPredictions(data):
  model = joblib.load('Models/RFC_model.pkl')
  
  y_pred = model.predict(data)
  pred_prob= model.predict_proba(data)
  

  
  return y_pred,pred_prob






if __name__ == '__main__':
    app.run(debug=True)